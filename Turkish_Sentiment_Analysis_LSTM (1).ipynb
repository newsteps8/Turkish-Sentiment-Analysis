{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Turkish_Sentiment_Analysis_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEVOskqGy7cM",
        "colab_type": "code",
        "outputId": "c92c0c18-b584-499e-df50-0dccc03a9f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfTos2DaxVIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('./drive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpFYBGhxGoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import emoji\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix, vstack\n",
        "import pickle\n",
        "#analyzer_emoji = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzzVl3fpWajt",
        "colab_type": "code",
        "outputId": "7ee29c16-7de5-4058-ba61-5867aa4ba852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Preprocessing for Twitter Datas\n",
        "\n",
        "'''Maybe nltk porter stemmer or punctuation can be try'''\n",
        "\n",
        "df['text'] = df['text'].astype(str).fillna(' ')\n",
        "# Lower case comment\n",
        "df['text'] = df['text'].str.lower()\n",
        "# Add num words of comment as feature\n",
        "#df['num_words'] = df['text'].apply(lambda s: len(s.split()))\n",
        "# Add num words unique of comment as feature\n",
        "#df['num_unique_words'] = df['text'].apply(lambda s: len(set(w for w in s.split())))\n",
        "# Add num words unique per num words of comment as feature\n",
        "#df['words_vs_unique'] = df['num_unique_words'] / df['num_words'] * 100\n",
        "# Add emojis features\n",
        "df['text'] = df['text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
        "print(\"Statistical features end!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistical features end!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbVkT9Kxhx1w",
        "colab_type": "code",
        "outputId": "f87a9450-d734-4d6b-e25e-14bbf938bf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Preprocessing for Twitter Datas\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('turkish')\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSaZJ1Pe7azb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"hepsiburada.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4xUrYhYxGoO",
        "colab_type": "code",
        "outputId": "a56eaca1-f8b0-43b4-dd81-8697054d40c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = data.copy()\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3 yıldır tık demedi. :)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3 yıldır kullanıyorum müthiş</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Ürün bugün elime geçti çok fazla inceleme fırs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Almaya karar verdim. Hemencecik geldi. Keyifle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Günlük kullanımınızı çok çok iyi karsılıyor kı...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating                                             Review\n",
              "0       1                            3 yıldır tık demedi. :)\n",
              "1       1                      3 yıldır kullanıyorum müthiş \n",
              "2       1  Ürün bugün elime geçti çok fazla inceleme fırs...\n",
              "3       1  Almaya karar verdim. Hemencecik geldi. Keyifle...\n",
              "4       1  Günlük kullanımınızı çok çok iyi karsılıyor kı..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9iTQ-8sEVQa",
        "colab_type": "code",
        "outputId": "a231fe9e-e42e-459d-a6bd-ef6f1c0ec6f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df['Rating'].unique().tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDqyJrEGxGoS",
        "colab_type": "code",
        "outputId": "ed4cec08-cbc2-454d-f079-72bdc2803703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM,  Dropout\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg2z2r-QxGoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all labels and reviews as a list\n",
        "target = df['Rating'].values.tolist()#negative=0, positive=1\n",
        "data = df['Review'].values.tolist()#text data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNHzPWddxGoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seperation = int(len(data) * 0.80)\n",
        "x_train, x_test = data[:seperation], data[seperation:]\n",
        "y_train, y_test = target[:seperation], target[seperation:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0EkOnfgxGop",
        "colab_type": "code",
        "outputId": "6854d17b-ca67-4460-ff18-a497763d3b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(243497, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUCLgvV4xGou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will get 10000 most frequently used words in our dataset\n",
        "num_words = 10000 #200000,100000,20000\n",
        "\n",
        "# Define tokenizer with Keras...\n",
        "# If we don't define num_words, then we use all words in our dataset.\n",
        "tokenizer = Tokenizer(num_words=num_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdmlloaixGoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now tokenize the data\n",
        "tokenizer.fit_on_texts(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG4phX_2xGo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving tokenizer\n",
        "import pickle\n",
        "\n",
        "with open('turkish_tokenizer_000.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kuky--VxGo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load tokenizer\n",
        "with open('turkish_tokenizer_000.pickle', 'rb') as handle:\n",
        "    turkish_tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-upV4lOxGpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Tokenize our training data. This will only works for the words in our 10000 tokenizer. \n",
        "If a word is not in 10000 tokenized words, it will be ignored.\n",
        "\"\"\"\n",
        "x_train_tokens = turkish_tokenizer.texts_to_sequences(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkN9jbQFxGpG",
        "colab_type": "code",
        "outputId": "1fdfc725-1d78-4ceb-8243-c27cf26be01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train[100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bu fiyata bu kalite kaçırmayın derim '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sGvRebixGpK",
        "colab_type": "code",
        "outputId": "e6464e6e-af17-448a-f223-93a56ef34c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "x_train_tokens[100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 39, 5, 131, 323, 143]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQU6PZoZxGpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_test_tokens = turkish_tokenizer.texts_to_sequences(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK269NvCxGpV",
        "colab_type": "code",
        "outputId": "3749ab98-3b0c-4180-8329-786f568ac8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "We will add Padding for our comments.\n",
        "In RNN, we give predefined-sized inputs. But our comments consist of different sized inputs, so we need to define\n",
        "a input size for comments. If size > comment, then add 0s for the gap, otherwise trim the comment.\n",
        "\"\"\"\n",
        "\n",
        "# How many tokens in each comment?\n",
        "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
        "\n",
        "# Convert list to numpy array\n",
        "num_tokens = np.array(num_tokens)\n",
        "num_tokens.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(243497,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebBLkLq5xGpa",
        "colab_type": "code",
        "outputId": "529a5821-49b9-4a1c-8d24-0ed5b9dfec43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# In average, how many tokens in one comment?\n",
        "np.mean(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.744703220162876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvQL3DhKxGpd",
        "colab_type": "code",
        "outputId": "2d1efc71-92ca-41ff-c716-95d90793633c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Max token amount?\n",
        "np.max(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRzu8iCgxGph",
        "colab_type": "code",
        "outputId": "0d364b9c-2941-4bb5-fd14-0b22c2f1bcdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Index of max token\n",
        "np.argmax(num_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21941"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhvkkVg3xGpl",
        "colab_type": "code",
        "outputId": "d9c0d46f-6f41-417b-b22f-cabffced7259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define max tokens for all comments\n",
        "max_tokens = np.mean(num_tokens) + 2*np.std(num_tokens) #returns float\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loXN__XvxGpp",
        "colab_type": "code",
        "outputId": "446aabb5-e6fc-4418-aff0-e5e293010af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# How many tokens are smaller than max_tokens?\n",
        "np.sum(num_tokens < max_tokens) / len(num_tokens) * 100  # output: 96%. which means we will only lose info in 4%."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.97982726686571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YOBiiaCxGpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's add paddings... So, all datas will be in the same size.\n",
        "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)\n",
        "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkE1r39MxGpw",
        "colab_type": "code",
        "outputId": "5f148617-0833-4845-9fb1-425a2b500995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Check the sizes\n",
        "print(x_train_pad.shape)\n",
        "print(x_test_pad.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(194797, 59)\n",
            "(48700, 59)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWMQL8-YxGp0",
        "colab_type": "code",
        "outputId": "d3aa78f5-4780-4fd9-ffeb-54221ad906d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# In Keras, we can get tokens from strings but not vice versa.\n",
        "# So we will write a function to get strings from tokens\n",
        "idx = turkish_tokenizer.word_index\n",
        "#print(idx)\n",
        "# in idx, key value pair like 'çok': 1. But we want it reverse.\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))\n",
        "first_five = {k: inverse_map[k] for k in sorted(inverse_map.keys())[:5]}\n",
        "first_five"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'çok', 2: 'bir', 3: 've', 4: 'ürün', 5: 'bu'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmIgnoVzxGp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_tokens_to_string(tokens):\n",
        "    words = [inverse_map[token] for token in tokens if token != 0]\n",
        "    text = ' '.join(words)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxKLFB9LxGp8",
        "colab_type": "code",
        "outputId": "8a8eb7cb-0538-47d9-e61d-3da0b37e83d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = Sequential() #define model\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nUBdP3ExGp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 50 # vector with 50 size for every word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Zc5iucxGqD",
        "colab_type": "code",
        "outputId": "ff288909-3244-4c84-ed05-7d0e9dbe3301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\"\"\"\n",
        "Now we will create an embedding layer in Keras.\n",
        "We won't use word2vec or glove, instead we create word vectors randomly.\n",
        "\"\"\"\n",
        "\n",
        "# Add embedding layer to our model.\n",
        "# embedding matris size = num_words * embedding_size -> 10.000 * 50\n",
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='embedding_layer'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGY7_X6xGqH",
        "colab_type": "code",
        "outputId": "a3a9f10f-9590-4b9b-a4ce-d60215a81b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# 3-layered LSTM\n",
        "model.add(LSTM(units=16, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=8, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=4, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "# Dense layer: aka fully connected layer. Consists of one neuron.\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEaDE7FXxGqL",
        "colab_type": "code",
        "outputId": "eae2f5a5-bcc4-4257-adac-aac1858a7b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "# Adam optimizer\n",
        "optimizer = Adam(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_D4Ifh-xGqQ",
        "colab_type": "code",
        "outputId": "05d8d16b-01a5-4b4c-a741-bd8bf848c3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "optimizer='adam',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQF-klTHxGqT",
        "colab_type": "code",
        "outputId": "bcb8eea3-4d7c-4d4e-ff45-88b4ca8d2ab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_layer (Embedding)  (None, 59, 50)            500000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 59, 16)            4288      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 59, 16)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 59, 8)             800       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 59, 8)             0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 4)                 208       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 505,301\n",
            "Trainable params: 505,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufjvJHGFxGqY",
        "colab_type": "code",
        "outputId": "eb2ca410-a1b7-4dce-c70a-d6429e17c0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# epoch -> how many times we are going to train our data.\n",
        "# batch_size -> feeding size\n",
        "model.fit(x_train_pad, y_train, epochs=10, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "194797/194797 [==============================] - 266s 1ms/step - loss: 0.2672 - acc: 0.9424\n",
            "Epoch 2/10\n",
            "194797/194797 [==============================] - 246s 1ms/step - loss: 0.1681 - acc: 0.9515\n",
            "Epoch 3/10\n",
            "194797/194797 [==============================] - 242s 1ms/step - loss: 0.1022 - acc: 0.9683\n",
            "Epoch 4/10\n",
            "194797/194797 [==============================] - 247s 1ms/step - loss: 0.0803 - acc: 0.9760\n",
            "Epoch 5/10\n",
            "194797/194797 [==============================] - 257s 1ms/step - loss: 0.0647 - acc: 0.9812\n",
            "Epoch 6/10\n",
            "194797/194797 [==============================] - 249s 1ms/step - loss: 0.0524 - acc: 0.9849\n",
            "Epoch 7/10\n",
            "194797/194797 [==============================] - 251s 1ms/step - loss: 0.0444 - acc: 0.9877\n",
            "Epoch 8/10\n",
            "194797/194797 [==============================] - 260s 1ms/step - loss: 0.0371 - acc: 0.9901\n",
            "Epoch 9/10\n",
            "194797/194797 [==============================] - 249s 1ms/step - loss: 0.0333 - acc: 0.9917\n",
            "Epoch 10/10\n",
            "194797/194797 [==============================] - 249s 1ms/step - loss: 0.0288 - acc: 0.9932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f18ed616048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiPqMvfOxGqb",
        "colab_type": "code",
        "outputId": "c02c1f4e-266f-49e2-be83-af614d839d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "result = model.evaluate(x_test_pad, y_test)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48700/48700 [==============================] - 171s 4ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24414843802609973, 0.9457905544147844]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivvk3CGaxGqj",
        "colab_type": "code",
        "outputId": "182eea25-69db-44f1-b032-94ee78b6594b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = (result[1]) * 100\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.57905544147845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHFwG3oYxGqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1 = \"büyük bir hayal kırıklığı yaşadım bu ürün bu markaya yakışmamış\"\n",
        "text2 = \"tasarımı harika ancak kargo çok geç geldi ve ürün açılmıştı tavsiye etmem :(\"\n",
        "text3 = \"hiç resimde gösterildiği gibi değil...\"\n",
        "text4 = \"kötü yorumlar gözümü korkutmuştu ancak hiçbir sorun yaşamadım teşekkürler\"\n",
        "text5 = \"hiç bu kadar kötü bir satıcıya denk gelmemiştim. ürünü iade ediyorum\"\n",
        "text6 = \"tam bir fiyat performans ürünü\"\n",
        "text7 = \"güzel bir ürün değil\"\n",
        "texts = [text1, text2,text3,text4,text5,text6,text7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRPAXDU4xGqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = turkish_tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVyix5EVxGqx",
        "colab_type": "code",
        "outputId": "f3fb3457-c2fa-4944-d012-12f476d6a020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tokens = turkish_tokenizer.texts_to_sequences(texts)\n",
        "tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[104, 2, 1032, 2333, 1466, 5, 4, 5, 1779],\n",
              " [553, 61, 82, 27, 1, 458, 33, 3, 4, 9, 1031],\n",
              " [46, 1096, 6419, 20, 50],\n",
              " [177, 735, 7728, 82, 263, 105, 326, 16],\n",
              " [46, 5, 30, 177, 2, 1717, 1244, 19, 677, 83],\n",
              " [74, 2, 28, 111, 19],\n",
              " [7, 2, 4, 50]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOB3Ly_0xGq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_pad = pad_sequences(tokens, maxlen=max_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFPD-WYRXgzS",
        "colab_type": "code",
        "outputId": "855dde0a-8d3d-4ef3-ed00-1e436fc53704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.predict(tokens_pad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00613517],\n",
              "       [0.08107951],\n",
              "       [0.00456542],\n",
              "       [0.9993015 ],\n",
              "       [0.0052653 ],\n",
              "       [0.99948347],\n",
              "       [0.96659845]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5GG92fRxGq4",
        "colab_type": "code",
        "outputId": "0030fea1-d2ee-4199-e3f0-1ed371405fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "for i in model.predict(tokens_pad):\n",
        "  if i < 0.5:\n",
        "    print(\"negative\")\n",
        "  elif i >= 0.5:\n",
        "    print(\"positive\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative\n",
            "negative\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIVZx4nIxGq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(texts):\n",
        "    tokens = turkish_tokenizer.texts_to_sequences(texts)\n",
        "    tokens_pad = pad_sequences(tokens, maxlen=max_tokens)\n",
        "    return model.predict(tokens_pad)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8obDvY1yMfZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('my_Model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "#del model  # deletes the existing model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "\n",
        "#load model\n",
        "#model = load_model('my_Model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}